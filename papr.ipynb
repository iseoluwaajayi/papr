{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6dbd6c-db9e-4f61-a3fd-f115a5f13f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the method that uses the MATLAB Engine API for Python\n",
    "import matlab.engine\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torchvision import  models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import timm, pickle\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from scipy.io import savemat\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c9a3ac-fe84-4ef2-9b3b-1abc71872199",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps') if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bcc4da-3c74-49b2-8398-587bd933337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be220735-ac4e-419e-b499-864df1d27ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_input = scio.loadmat('algorithm_input_.mat')\n",
    "algorithm_input_mat = algorithm_input['algorithm_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f6bc0b-09d2-4bb3-b8b7-7d577e69f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_output = scio.loadmat('algorithm_output_.mat')\n",
    "algorithm_output_mat = algorithm_output['algorithm_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804a0f6e-28e3-4a77-be88-76d7319e4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_channels = scio.loadmat('main_channels_.mat')\n",
    "main_channels_mat = main_channels['main_channels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56727a05-a21d-4dd7-ab23-599b1d81b05e",
   "metadata": {},
   "source": [
    "main_channels_mat = torch.load('main_channels_tensor.pt', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c30e94-9921-4ef9-9335-e913b68cf9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_store = scio.loadmat('symbols_store_.mat')\n",
    "symbols_store_mat = symbols_store['symbols_store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4dedec3-a4de-43cc-ba30-fb37b8d9a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.algorithm_input_mat = algorithm_input_mat\n",
    "        self.algorithm_output_mat = algorithm_output_mat\n",
    "        self.main_channels_mat = main_channels_mat\n",
    "        self.symbols_store_mat = symbols_store_mat\n",
    "        \n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.algorithm_input_mat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        algorithm_input_mat = self.algorithm_input_mat[idx,:]\n",
    "        algorithm_output_mat = self.algorithm_output_mat[idx,:]\n",
    "        main_channels_mat = self.main_channels_mat[idx,:,:]\n",
    "        symbols_store_mat = self.symbols_store_mat[idx,:]\n",
    "        return algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2a537d-4f72-4525-9d55-3f479405587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae911b39-4580-44fe-81de-864892143bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the dataset into train and remaining (val + test)\n",
    "train_set, remaining_set = train_test_split(dataset, test_size=20000, random_state=42)\n",
    "\n",
    "# Now, split the remaining set into validation and test sets\n",
    "val_set, test_set = train_test_split(remaining_set, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b372d6-28d2-4e1b-b2c7-4ecc3f46c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2425bdd-3cfc-4088-9f70-28db15772818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of batch feature is torch.Size([64, 70])\n",
      "shape of batch feature is torch.Size([64, 70])\n",
      "shape of batch feature is torch.Size([64, 10, 70])\n",
      "shape of batch feature is torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_alg_in_mat, batch_alg_out_mat, batch_main_chan_mat, batch_sym_mat = next(iter(train_loader))\n",
    "print(f'shape of batch feature is {batch_alg_in_mat.shape}')\n",
    "print(f'shape of batch feature is {batch_alg_out_mat.shape}')\n",
    "print(f'shape of batch feature is {batch_main_chan_mat.shape}')\n",
    "print(f'shape of batch feature is {batch_sym_mat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e0a58e-4083-4f92-a375-da27fcd11eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_interleaved_real(complex_signal):\n",
    "    real_part = complex_signal.real.to(dtype=torch.float32) \n",
    "    imag_part = complex_signal.imag.to(dtype=torch.float32) \n",
    "    interleaved_signal = torch.stack((real_part, imag_part), dim=2).reshape(complex_signal.shape[0], -1)\n",
    "    return interleaved_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1c6bd0-3830-41ee-8f79-168a01a7530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleaved_real_to_complex(interleaved_signal):\n",
    "    signal_length = interleaved_signal.shape[1] // 2\n",
    "    real_part = interleaved_signal[:, 0::2]  # Extract even indices\n",
    "    imag_part = interleaved_signal[:, 1::2]  # Extract odd indices\n",
    "    complex_signal = torch.complex(real_part, imag_part)\n",
    "    return complex_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d85abef5-3c5a-474f-aee1-1761ae32f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_papr_complex(signal):\n",
    "    # Compute |x[n]|^2: Magnitude squared of the complex signal\n",
    "    power_signal = torch.abs(signal)**2\n",
    "    \n",
    "    # Peak power\n",
    "    peak_power_signal= torch.max(power_signal, dim=1).values\n",
    "\n",
    "    # Average power\n",
    "    avg_power_signal = torch.mean(power_signal, dim=1)\n",
    "\n",
    "    # PAPR\n",
    "    papr_signal = peak_power_signal / avg_power_signal\n",
    "    \n",
    "    return papr_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b9bb3f2-4dc6-4155-a8da-627445761686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def papr_loss(signal_going_out, signal_coming_in):\n",
    "    # Compute PAPR before and after\n",
    "    papr_going_out = compute_papr_complex(signal_going_out)  # Transformed signal\n",
    "    papr_coming_in = compute_papr_complex(signal_coming_in)  # Original signal\n",
    "\n",
    "    # Penalize only if PAPR after is greater than PAPR before\n",
    "    papr_diff = torch.relu(papr_going_out - papr_coming_in)\n",
    "    \n",
    "    return torch.mean(papr_diff), torch.mean(papr_going_out), torch.mean(papr_coming_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d9eb3a-3856-4452-805e-ca119bfacdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_matlab(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat):\n",
    "    \n",
    "    batch_alg_in_mat_real = matlab.double(batch_alg_in_mat.real.tolist())\n",
    "    batch_alg_in_mat_imag = matlab.double(batch_alg_in_mat.imag.tolist())\n",
    "\n",
    "    batch_alg_out_mat_real = matlab.double(batch_alg_out_mat.real.tolist())\n",
    "    batch_alg_out_mat_imag = matlab.double(batch_alg_out_mat.imag.tolist())\n",
    "\n",
    "    batch_nn_out_real = matlab.double(batch_nn_out.real.tolist())\n",
    "    batch_nn_out_imag = matlab.double(batch_nn_out.imag.tolist())\n",
    "\n",
    "    batch_main_chan_mat_real = matlab.double(batch_main_chan_mat.real.tolist())\n",
    "    batch_main_chan_mat_imag = matlab.double(batch_main_chan_mat.imag.tolist())\n",
    "\n",
    "    batch_sym_mat = matlab.uint32(batch_sym_mat.tolist())\n",
    "\n",
    "    return batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag, batch_sym_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c00e4fa-534d-4ae9-977d-c5cca46a7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ser_loss(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat):\n",
    "\n",
    "    batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag , batch_sym_mat = prepare_for_matlab(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat)\n",
    "    ser_mat = eng.calculate_ser(batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag , batch_sym_mat)\n",
    "    ser_torch = torch.tensor(ser_mat, dtype=torch.float32)\n",
    "    ser_diff = torch.relu(ser_torch[:,2] - ser_torch[:,1])\n",
    "    return torch.mean(ser_diff), torch.mean(ser_torch[:,2]), torch.mean(ser_torch[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fbc824a-e50a-4f62-a221-12b15d8a39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_complex_autocorrelation(signals):\n",
    "    signals_conj = torch.conj(signals)  # Compute complex conjugate\n",
    "    results = torch.zeros((signals.size(0), signals.size(1)), dtype=torch.cfloat)  # Output buffer\n",
    "    \n",
    "    for i in range(signals.size(0)):  # Process each signal in the batch\n",
    "        signal = signals[i]\n",
    "        signal_conj = signals_conj[i]\n",
    "        # Compute convolution (autocorrelation via convolution)\n",
    "        result = torch.nn.functional.conv1d(\n",
    "            signal.view(1, 1, -1),\n",
    "            signal_conj.flip(0).view(1, 1, -1),\n",
    "            padding=signal.size(0) - 1,\n",
    "        )\n",
    "        results[i] = result.view(-1)[signal.size(0) - 1:]  # Keep only positive lags\n",
    "\n",
    "    # Separate magnitude and phase for the batch\n",
    "    magnitudes = torch.abs(results)  # Shape: (batch_size, signal_length)\n",
    "    phases = torch.angle(results)    # Shape: (batch_size, signal_length)\n",
    "\n",
    "    # Create 2D autocorrelation maps for each signal in the batch\n",
    "    auto_maps_real = torch.einsum('bi,bj->bij', torch.real(results), torch.real(results))\n",
    "    auto_maps_imag = torch.einsum('bi,bj->bij', torch.imag(results), torch.imag(results))\n",
    "    auto_maps_mag = torch.einsum('bi,bj->bij', magnitudes, magnitudes)  # Outer product: (batch_size, signal_length, signal_length)\n",
    "    auto_maps_phase = torch.einsum('bi,bj->bij', phases, phases)  # Outer product: (batch_size, signal_length, signal_length)\n",
    "\n",
    "    # Normalize maps to [0, 1]\n",
    "    auto_maps_real_normalized = (auto_maps_real - auto_maps_real.min()) / (auto_maps_real.max() - auto_maps_real.min())\n",
    "    auto_maps_imag_normalized = (auto_maps_imag - auto_maps_imag.min()) / (auto_maps_imag.max() - auto_maps_imag.min())\n",
    "    auto_maps_mag_normalized = (auto_maps_mag - auto_maps_mag.min()) / (auto_maps_mag.max() - auto_maps_mag.min())\n",
    "    auto_maps_phase_normalized = (auto_maps_phase - auto_maps_phase.min()) / (auto_maps_phase.max() - auto_maps_phase.min())\n",
    "\n",
    "    output = torch.cat([auto_maps_real_normalized.unsqueeze(1), auto_maps_imag_normalized.unsqueeze(1), auto_maps_mag_normalized.unsqueeze(1), auto_maps_phase_normalized.unsqueeze(1)], dim = 1)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6184ba22-19fb-45d0-8f85-b22d7154707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 70])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_alg_out_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "477272b0-eec4-44ca-a3d8-3da043e9716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_out = batch_complex_autocorrelation(batch_alg_out_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b5cacf-3d01-4e47-a402-6190caaf6933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 70, 70])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5466786c-718c-4e14-8f8b-6d95defefb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBased(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelBased, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(140, 70)\n",
    "        self.bn1 = nn.BatchNorm1d(70)\n",
    "        \n",
    "        self.linear2 = nn.Linear(70, 35)\n",
    "        self.bn2 = nn.BatchNorm1d(35)\n",
    "        \n",
    "        self.linear3 = nn.Linear(35, 70)\n",
    "        self.bn3 = nn.BatchNorm1d(70)\n",
    "        \n",
    "        self.linear4 = nn.Linear(70, 140)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(1)\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = F.relu(self.bn2(self.linear2(x)))\n",
    "        x = F.relu(self.bn3(self.linear3(x)))\n",
    "        x = self.linear4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae4ad62-ff33-43ec-b993-c89094ad534c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 140])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_shape = ModelBased()(torch.rand([64,140])).shape\n",
    "test_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2de6162e-90aa-4935-a238-ba7fef9c4d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10] T Loss:1.1527 PAPR_dff: 0.0159 NN_PAPR: 1.7157 Alg_PAPR: 2.1162 SER_dff: 0.9172 NN_SER: 0.9187 Alg_SER: 0.0016 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10] V Loss:0.0349 PAPR_dff: 0.0000 NN_PAPR: 1.6378 Alg_PAPR: 2.0487 SER_dff: 0.9250 NN_SER: 0.9250 Alg_SER: 0.0000: 100%|█| 157/157 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0349 at Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10] T Loss:0.9569 PAPR_dff: 0.0000 NN_PAPR: 1.6003 Alg_PAPR: 2.1451 SER_dff: 0.9469 NN_SER: 0.9484 Alg_SER: 0.0016 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10] V Loss:0.0129 PAPR_dff: 0.0000 NN_PAPR: 1.6109 Alg_PAPR: 2.0487 SER_dff: 0.9562 NN_SER: 0.9563 Alg_SER: 0.0000: 100%|█| 157/157 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0129 at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10] T Loss:0.9467 PAPR_dff: 0.0000 NN_PAPR: 1.5914 Alg_PAPR: 2.1056 SER_dff: 0.9437 NN_SER: 0.9453 Alg_SER: 0.0016 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10] V Loss:0.0091 PAPR_dff: 0.0000 NN_PAPR: 1.5993 Alg_PAPR: 2.0487 SER_dff: 0.9375 NN_SER: 0.9375 Alg_SER: 0.0000: 100%|█| 157/157 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0091 at Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10] T Loss:0.9449 PAPR_dff: 0.0000 NN_PAPR: 1.5793 Alg_PAPR: 2.0928 SER_dff: 0.9406 NN_SER: 0.9422 Alg_SER: 0.0016 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10] V Loss:0.0084 PAPR_dff: 0.0000 NN_PAPR: 1.5751 Alg_PAPR: 2.0487 SER_dff: 0.9375 NN_SER: 0.9438 Alg_SER: 0.0063: 100%|█| 157/157 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0084 at Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10] T Loss:0.9440 PAPR_dff: 0.0000 NN_PAPR: 1.6034 Alg_PAPR: 2.0827 SER_dff: 0.9375 NN_SER: 0.9375 Alg_SER: 0.0000 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10] V Loss:0.0077 PAPR_dff: 0.0000 NN_PAPR: 1.6065 Alg_PAPR: 2.0487 SER_dff: 0.9750 NN_SER: 0.9750 Alg_SER: 0.0000: 100%|█| 157/157 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0077 at Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10] T Loss:0.9616 PAPR_dff: 0.0000 NN_PAPR: 1.6961 Alg_PAPR: 2.1063 SER_dff: 0.9391 NN_SER: 0.9391 Alg_SER: 0.0000 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10] V Loss:0.0203 PAPR_dff: 0.0000 NN_PAPR: 1.6944 Alg_PAPR: 2.0487 SER_dff: 0.9437 NN_SER: 0.9438 Alg_SER: 0.0000: 100%|█| 157/157 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Epoch: 1 without improvement\n",
      "Current Validation Loss is: 0.0203 at Epoch: 6\n",
      "Best Validation Loss remains: 0.0077 at Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10] T Loss:0.9533 PAPR_dff: 0.0000 NN_PAPR: 1.7162 Alg_PAPR: 2.0936 SER_dff: 0.9453 NN_SER: 0.9453 Alg_SER: 0.0000 LR is 0.001:  97%|▉| 1215"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Update running loss\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m running_train_loss \u001b[38;5;241m/\u001b[39m (index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Get current learning rate from the optimizer\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ModelBased().to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "loss = torch.nn.MSELoss()  # For classification\n",
    "\n",
    "# Define an optimizer (both for the encoder and the decoder!)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.01)  # Learning rate decay scheduler\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2)\n",
    "\n",
    "# Variables for early stopping and best parameters\n",
    "best_loss = float('inf')\n",
    "patience_limit = 3\n",
    "\n",
    "\n",
    "best_model = None\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "gamma = 1\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    progress_bar_train = tqdm(enumerate(train_loader), total=len(train_loader), ncols=150)\n",
    "    for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_train:\n",
    "        # Forward pass\n",
    "        #algorithm_output_mat_for_nn = (batch_complex_autocorrelation(algorithm_output_mat)).to(device)\n",
    "        algorithm_input_mat_for_nn = (complex_to_interleaved_real(algorithm_input_mat)).to(device)\n",
    "        algorithm_output_mat_for_nn = (complex_to_interleaved_real(algorithm_output_mat)).to(device)\n",
    "\n",
    "        \n",
    "        nn_output = model(algorithm_input_mat_for_nn)\n",
    "        \n",
    "        # Calculate loss\n",
    "        initial_loss = loss(nn_output, algorithm_output_mat_for_nn)\n",
    "\n",
    "        nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "        algorithm_output_mat_for_nn_control =  interleaved_real_to_complex(algorithm_output_mat_for_nn)\n",
    "        \n",
    "        papr_diff, nn_papr, alg_papr  = papr_loss(nn_output_control, algorithm_output_mat_for_nn_control)\n",
    "        ser_diff, nn_ser, alg_ser = ser_loss(algorithm_input_mat, algorithm_output_mat_for_nn_control, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "        \n",
    "        train_loss = alpha*initial_loss + beta*papr_diff + gamma*ser_diff\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_train_loss += train_loss.item()\n",
    "        avg_train_loss = running_train_loss / (index + 1)\n",
    "\n",
    "        # Get current learning rate from the optimizer\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Print metrics\n",
    "        #progress_bar_train.set_description(f'Epoch [{epoch + 1}/{EPOCHS}] MSELos:{avg_train_loss1:.4f} MSEWeig{mse_weight:.2f} CELos:{avg_train_loss2:.4f} CEWeig{ce_weight:.2f} TrLos:{avg_train_loss:.4f} Tr.Acc: {avg_train_acc*100:.2f}%')\n",
    "        progress_bar_train.set_description(f\" Epoch [{epoch + 1}/{EPOCHS}] T Loss:{avg_train_loss:.4f} PAPR_dff: {papr_diff:.4f} NN_PAPR: {nn_papr:.4f} Alg_PAPR: {alg_papr:.4f} SER_dff: {ser_diff:.4f} NN_SER: {nn_ser:.4f} Alg_SER: {alg_ser:.4f} LR is {current_lr}\")\n",
    "    \n",
    "    #train_losses.append(avg_train_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Training has completed epoch {epoch+1}\")\n",
    "    \n",
    "    # Validation loop\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    progress_bar_val = tqdm(enumerate(val_loader), total=len(val_loader), ncols=150)\n",
    "    for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_val:\n",
    "        \n",
    "        #algorithm_output_mat_for_nn = (batch_complex_autocorrelation(algorithm_output_mat)).to(device)\n",
    "        algorithm_input_mat_for_nn = (complex_to_interleaved_real(algorithm_input_mat)).to(device)\n",
    "        algorithm_output_mat_for_nn = (complex_to_interleaved_real(algorithm_output_mat)).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            nn_output = model(algorithm_input_mat_for_nn)\n",
    "\n",
    "            # Calculate losses\n",
    "            val_loss = loss(nn_output, algorithm_output_mat_for_nn)\n",
    "\n",
    "            # Update running loss\n",
    "            running_val_loss += val_loss.item()\n",
    "            \n",
    "            avg_val_loss = running_val_loss / (index + 1)\n",
    "\n",
    "            nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "            algorithm_output_mat_for_nn_control =  interleaved_real_to_complex(algorithm_output_mat_for_nn)\n",
    "        \n",
    "            papr_diff, nn_papr, alg_papr = papr_loss(nn_output_control, algorithm_output_mat_for_nn_control)\n",
    "            ser_diff, nn_ser, alg_ser = ser_loss(algorithm_input_mat, algorithm_output_mat_for_nn_control, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "\n",
    "            progress_bar_val.set_description(f\" Epoch [{epoch + 1}/{EPOCHS}] V Loss:{avg_val_loss:.4f} PAPR_dff: {papr_diff:.4f} NN_PAPR: {nn_papr:.4f} Alg_PAPR: {alg_papr:.4f} SER_dff: {ser_diff:.4f} NN_SER: {nn_ser:.4f} Alg_SER: {alg_ser:.4f}\")\n",
    "    \n",
    "    #val_losses.append(avg_val_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    scheduler.step(running_val_loss)\n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_loss:  # Now checking for the best accuracy\n",
    "        best_loss = avg_val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        best_train_loss = avg_train_loss\n",
    "        patience_ = 0\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "        print(f\"Best Validation Loss is now: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "    else:\n",
    "        patience_ += 1\n",
    "        print(f\"This is Epoch: {patience_} without improvement\")\n",
    "        print(f\"Current Validation Loss is: {avg_val_loss:.4f} at Epoch: {epoch+1}\")\n",
    "        print(f\"Best Validation Loss remains: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "        if patience_ > patience_limit:  # Patience limit before stopping\n",
    "            print(\"Early stopping triggered! Restoring best model weights.\")\n",
    "            print(f\"Best Validation Loss was: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "            break\n",
    "\n",
    "best_model = model.cpu()\n",
    "best_model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332df58c-e6e1-4ee8-a14d-e6d44f34b32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93037367-17c0-4210-8978-48ffdf1f66bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a0ddb-8e26-4d34-aca8-482c79277896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b5174-b47c-4c19-a64e-35f0e497d4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a17176-6963-4e52-80b5-890d294583f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250c2ce-3932-42aa-88a2-27e0ddf495c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3906b8-dff2-4c7c-829b-da9345f8393b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d1e4b-ac4a-47e9-b945-43c6be86cf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "416c8758-d4ed-44be-8a0e-625dbff9cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBased(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelBased, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(1)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(4900,280*2)\n",
    "        self.bnfc1 = nn.BatchNorm1d(280*2)\n",
    "\n",
    "        self.linear2 = nn.Linear(280*2,140)\n",
    "        \n",
    "        #self.linear1 = nn.Linear(140, 280)\n",
    "        #self.bn1 = nn.BatchNorm1d(280)\n",
    "        \n",
    "        #self.linear2 = nn.Linear(280, 560)\n",
    "        #self.bn2 = nn.BatchNorm1d(560)\n",
    "        \n",
    "        #self.linear3 = nn.Linear(560, 280)\n",
    "        #self.bn3 = nn.BatchNorm1d(280)\n",
    "        \n",
    "        #self.linear4 = nn.Linear(280, 140)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(self.bnfc1(x))\n",
    "        x = self.linear2(x)\n",
    "        #x = F.relu(self.bn1(self.linear1(x)))\n",
    "        #x = F.relu(self.bn2(self.linear2(x)))\n",
    "        #x = F.relu(self.bn3(self.linear3(x)))\n",
    "        #x = self.linear4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfaf403d-3b00-46bc-9ce9-1d0e11092438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 140])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_shape = ModelBased()(torch.rand([64,4,70,70])).shape\n",
    "test_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc196a67-5169-4972-a723-4077999468e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 140])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelBased().to(device)\n",
    "test_data = torch.rand([64,4,70,70]).to(device)\n",
    "test_output = model(test_data)\n",
    "test_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94ced050-fea9-4688-85db-309ea7b31a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10] T Loss:5.5729 PAPR_dff: 0.0195 NN_PAPR: 2.5187 Alg_PAPR: 3.9536 SER_dff: 0.5031 NN_SER: 0.9234 Alg_SER: 0.4203 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10] V Loss:0.1621 PAPR_dff: 0.0000 NN_PAPR: 2.7967 Alg_PAPR: 3.7063 SER_dff: 0.6000 NN_SER: 0.937500 Alg_SER: 0.3375: 100%|█| 157/157 [00:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.1621 at Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10] T Loss:5.4297 PAPR_dff: 0.0000 NN_PAPR: 2.6551 Alg_PAPR: 3.9222 SER_dff: 0.5344 NN_SER: 0.9500 Alg_SER: 0.4156 LR is 0.001: 100%|█| 1250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10] V Loss:0.0080 PAPR_dff: 0.0000 NN_PAPR: 2.6582 Alg_PAPR: 3.7063 SER_dff: 0.5750 NN_SER: 0.937500 Alg_SER: 0.3625: 100%|█| 157/157 [00:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0080 at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10] T Loss:5.4165 PAPR_dff: 0.0000 NN_PAPR: 2.7507 Alg_PAPR: 3.8359 SER_dff: 0.5672 NN_SER: 0.9391 Alg_SER: 0.3719 LR is 0.001:  98%|▉| 1224"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m nn_output_control \u001b[38;5;241m=\u001b[39m  interleaved_real_to_complex(nn_output)\n\u001b[1;32m     46\u001b[0m papr_diff, nn_papr, alg_papr  \u001b[38;5;241m=\u001b[39m papr_loss(nn_output_control, algorithm_output_mat_for_nn_compare)\n\u001b[0;32m---> 47\u001b[0m ser_diff, nn_ser, alg_ser \u001b[38;5;241m=\u001b[39m \u001b[43mser_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgorithm_input_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm_output_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_output_control\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_channels_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols_store_mat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m alpha\u001b[38;5;241m*\u001b[39minitial_loss \u001b[38;5;241m+\u001b[39m beta\u001b[38;5;241m*\u001b[39mpapr_diff \u001b[38;5;241m+\u001b[39m gamma\u001b[38;5;241m*\u001b[39mser_diff\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m, in \u001b[0;36mser_loss\u001b[0;34m(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mser_loss\u001b[39m(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat):\n\u001b[0;32m----> 3\u001b[0m     batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag , batch_sym_mat \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_for_matlab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_alg_in_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_alg_out_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_nn_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_main_chan_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sym_mat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     ser_mat \u001b[38;5;241m=\u001b[39m eng\u001b[38;5;241m.\u001b[39mcalculate_ser(batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag , batch_sym_mat)\n\u001b[1;32m      5\u001b[0m     ser_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(ser_mat, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mprepare_for_matlab\u001b[0;34m(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat)\u001b[0m\n\u001b[1;32m      6\u001b[0m batch_alg_out_mat_real \u001b[38;5;241m=\u001b[39m matlab\u001b[38;5;241m.\u001b[39mdouble(batch_alg_out_mat\u001b[38;5;241m.\u001b[39mreal\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      7\u001b[0m batch_alg_out_mat_imag \u001b[38;5;241m=\u001b[39m matlab\u001b[38;5;241m.\u001b[39mdouble(batch_alg_out_mat\u001b[38;5;241m.\u001b[39mimag\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m----> 9\u001b[0m batch_nn_out_real \u001b[38;5;241m=\u001b[39m matlab\u001b[38;5;241m.\u001b[39mdouble(\u001b[43mbatch_nn_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m batch_nn_out_imag \u001b[38;5;241m=\u001b[39m matlab\u001b[38;5;241m.\u001b[39mdouble(batch_nn_out\u001b[38;5;241m.\u001b[39mimag\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     12\u001b[0m batch_main_chan_mat_real \u001b[38;5;241m=\u001b[39m matlab\u001b[38;5;241m.\u001b[39mdouble(batch_main_chan_mat\u001b[38;5;241m.\u001b[39mreal\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ModelBased().to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "loss = torch.nn.MSELoss()  # For classification\n",
    "\n",
    "# Define an optimizer (both for the encoder and the decoder!)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.01)  # Learning rate decay scheduler\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2)\n",
    "\n",
    "# Variables for early stopping and best parameters\n",
    "best_loss = float('inf')\n",
    "patience_limit = 3\n",
    "\n",
    "\n",
    "best_model = None\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "gamma = 10\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    progress_bar_train = tqdm(enumerate(train_loader), total=len(train_loader), ncols=150)\n",
    "    for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_train:\n",
    "        # Forward pass\n",
    "        algorithm_output_mat_for_nn = (batch_complex_autocorrelation(algorithm_output_mat)).to(device)\n",
    "        algorithm_output_mat_for_nn_compare = (complex_to_interleaved_real(algorithm_output_mat)).to(device)\n",
    "\n",
    "        \n",
    "        nn_output = model(algorithm_output_mat_for_nn)\n",
    "        \n",
    "        # Calculate loss\n",
    "        initial_loss = loss(nn_output, algorithm_output_mat_for_nn_compare)\n",
    "\n",
    "        nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "        \n",
    "        papr_diff, nn_papr, alg_papr  = papr_loss(nn_output_control, algorithm_output_mat_for_nn_compare)\n",
    "        ser_diff, nn_ser, alg_ser = ser_loss(algorithm_input_mat, algorithm_output_mat, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "        \n",
    "        train_loss = alpha*initial_loss + beta*papr_diff + gamma*ser_diff\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_train_loss += train_loss.item()\n",
    "        avg_train_loss = running_train_loss / (index + 1)\n",
    "\n",
    "        # Get current learning rate from the optimizer\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Print metrics\n",
    "        #progress_bar_train.set_description(f'Epoch [{epoch + 1}/{EPOCHS}] MSELos:{avg_train_loss1:.4f} MSEWeig{mse_weight:.2f} CELos:{avg_train_loss2:.4f} CEWeig{ce_weight:.2f} TrLos:{avg_train_loss:.4f} Tr.Acc: {avg_train_acc*100:.2f}%')\n",
    "        progress_bar_train.set_description(f\" Epoch [{epoch + 1}/{EPOCHS}] T Loss:{avg_train_loss:.4f} PAPR_dff: {papr_diff:.4f} NN_PAPR: {nn_papr:.4f} Alg_PAPR: {alg_papr:.4f} SER_dff: {ser_diff:.4f} NN_SER: {nn_ser:.4f} Alg_SER: {alg_ser:.4f} LR is {current_lr}\")\n",
    "    \n",
    "    #train_losses.append(avg_train_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Training has completed epoch {epoch+1}\")\n",
    "    \n",
    "    # Validation loop\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    progress_bar_val = tqdm(enumerate(val_loader), total=len(val_loader), ncols=150)\n",
    "    for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_val:\n",
    "        \n",
    "        algorithm_output_mat_for_nn = (batch_complex_autocorrelation(algorithm_output_mat)).to(device)\n",
    "        algorithm_output_mat_for_nn_compare = (complex_to_interleaved_real(algorithm_output_mat)).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            nn_output = model(algorithm_output_mat_for_nn)\n",
    "\n",
    "            # Calculate losses\n",
    "            val_loss = loss(nn_output, algorithm_output_mat_for_nn_compare)\n",
    "\n",
    "            # Update running loss\n",
    "            running_val_loss += val_loss.item()\n",
    "            \n",
    "            avg_val_loss = running_val_loss / (index + 1)\n",
    "\n",
    "            nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "        \n",
    "            papr_diff, nn_papr, alg_papr = papr_loss(nn_output_control, algorithm_output_mat_for_nn_compare)\n",
    "            ser_diff, nn_ser, alg_ser = ser_loss(algorithm_input_mat, algorithm_output_mat, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "\n",
    "            progress_bar_val.set_description(f\" Epoch [{epoch + 1}/{EPOCHS}] V Loss:{avg_val_loss:.4f} PAPR_dff: {papr_diff:.4f} NN_PAPR: {nn_papr:.4f} Alg_PAPR: {alg_papr:.4f} SER_dff: {ser_diff:.4f} NN_SER: {nn_ser:.4f} Alg_SER: {alg_ser:.4f}\")\n",
    "    \n",
    "    #val_losses.append(avg_val_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    scheduler.step(running_val_loss)\n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_loss:  # Now checking for the best accuracy\n",
    "        best_loss = avg_val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        best_train_loss = avg_train_loss\n",
    "        patience_ = 0\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "        print(f\"Best Validation Loss is now: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "    else:\n",
    "        patience_ += 1\n",
    "        print(f\"This is Epoch: {patience_} without improvement\")\n",
    "        print(f\"Current Validation Loss is: {avg_val_loss:.4f} at Epoch: {epoch+1}\")\n",
    "        print(f\"Best Validation Loss remains: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "        if patience_ > patience_limit:  # Patience limit before stopping\n",
    "            print(\"Early stopping triggered! Restoring best model weights.\")\n",
    "            print(f\"Best Validation Loss was: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "            break\n",
    "\n",
    "best_model = model.cpu()\n",
    "best_model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b9432-9787-4c17-ab5c-d7d6378506d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "running_test_loss = 0.0\n",
    "\n",
    "\n",
    "progress_bar_test = tqdm(enumerate(test_loader), total=len(test_loader), ncols=100, leave=True)\n",
    "for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_test:\n",
    "        \n",
    "    algorithm_output_mat_for_nn = complex_to_interleaved_real(algorithm_output_mat)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            \n",
    "        nn_output = best_model(algorithm_output_mat_for_nn)\n",
    "\n",
    "        # Calculate losses\n",
    "        test_loss = loss(nn_output, algorithm_output_mat_for_nn)\n",
    "\n",
    "        # Update running loss\n",
    "        running_test_loss += test_loss.item()\n",
    "            \n",
    "        avg_test_loss = running_test_loss / (index + 1)\n",
    "\n",
    "        nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "        \n",
    "        papr_diff = papr_loss(nn_output_control, algorithm_output_mat_for_nn)\n",
    "        ser_diff = ser_loss(algorithm_input_mat, algorithm_output_mat, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "\n",
    "        progress_bar_test.set_description(f'Epoch [{epoch + 1}/{EPOCHS}] Te Loss:{avg_test_loss:.4f} PAPR_dff: {papr_diff:.4f} SER_dff: {ser_diff:.4f}')\n",
    "\n",
    "        \n",
    "        if index < 1:\n",
    "            total_nn_out = nn_output\n",
    "            total_alg_in = algorithm_input_mat\n",
    "            total_alg_out = algorithm_output_mat\n",
    "            total_main_channels = main_channels_mat\n",
    "            total_symbols = symbols_store_mat\n",
    "        else:\n",
    "            total_nn_out = torch.cat([total_nn_out, nn_output], dim=0, out=None)\n",
    "            total_alg_in = torch.cat([total_alg_in, algorithm_input_mat], dim=0, out=None)\n",
    "            total_alg_out = torch.cat([total_alg_out, algorithm_output_mat], dim=0, out=None)\n",
    "            total_main_channels = torch.cat([total_main_channels, main_channels_mat], dim=0, out=None)\n",
    "            total_symbols = torch.cat([total_symbols, symbols_store_mat], dim=0, out=None)\n",
    "\n",
    "\n",
    "        progress_bar_val.set_description(f'Epoch [{epoch + 1}/{EPOCHS}] Te Loss:{avg_test_loss:.4f} PAPR_dff: {papr_diff:.4f} SER_dff: {ser_diff:.4f}')\n",
    "    \n",
    "test_losses.append(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f020a4-b573-4f70-8d66-dab90fc0de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_alg_in_real, total_alg_in_imag, total_alg_out_real, total_alg_out_imag, total_nn_out_real, total_nn_out_imag, total_main_channels_real, total_main_channels_imag, total_symbols = prepare_for_matlab(total_alg_in, total_alg_out, total_nn_out, total_main_channels, total_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d677f-c655-4a98-9636-1955d4cdc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all variables in a dictionary\n",
    "savemat(\"output_from_pytorch.mat\", {\n",
    "    \"total_alg_in_real\": total_alg_in_real,\n",
    "    \"total_alg_in_imag\": total_alg_in_imag,\n",
    "    \"total_alg_out_real\": total_alg_out_real,\n",
    "    \"total_alg_out_imag\": total_alg_out_imag,\n",
    "    \"total_nn_out_real\": total_nn_out_real,\n",
    "    \"total_nn_out_imag\": total_nn_out_imag,\n",
    "    \"total_main_channels_real\": total_main_channels_real,\n",
    "    \"total_main_channels_imag\": total_main_channels_imag,\n",
    "    \"total_symbols\": total_symbols\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e49995-da2d-4b44-ad81-59217a411746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
