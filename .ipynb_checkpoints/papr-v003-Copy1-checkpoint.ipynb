{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6dbd6c-db9e-4f61-a3fd-f115a5f13f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the method that uses the MATLAB Engine API for Python\n",
    "import matlab.engine\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torchvision import  models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import timm\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from scipy.io import savemat\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c9a3ac-fe84-4ef2-9b3b-1abc71872199",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps') if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bcc4da-3c74-49b2-8398-587bd933337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be220735-ac4e-419e-b499-864df1d27ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_input = scio.loadmat('algorithm_input_single.mat')\n",
    "algorithm_input_mat = algorithm_input['algorithm_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f6bc0b-09d2-4bb3-b8b7-7d577e69f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_output = scio.loadmat('algorithm_output_single.mat')\n",
    "algorithm_output_mat = algorithm_output['algorithm_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68323569-4b73-4610-93e8-15c91ffe05b5",
   "metadata": {},
   "source": [
    "main_channels = scio.loadmat('main_channels_.mat')\n",
    "main_channels_mat = main_channels['main_channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c4428-78bd-49a9-b241-e672312cd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_channels_mat = torch.load('main_channels_tensor.pt', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb26fa-9676-46ad-9f34-f13421cb1887",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_store = scio.loadmat('symbols_store.mat')\n",
    "symbols_store_mat = symbols_store['symbols_store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4dedec3-a4de-43cc-ba30-fb37b8d9a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.algorithm_input_mat = algorithm_input_mat\n",
    "        self.algorithm_output_mat = algorithm_output_mat\n",
    "        self.main_channels_mat = main_channels_mat\n",
    "        self.symbols_store_mat = symbols_store_mat\n",
    "        \n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.algorithm_input_mat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        algorithm_input_mat = self.algorithm_input_mat[idx,:]\n",
    "        algorithm_output_mat = self.algorithm_output_mat[idx,:]\n",
    "        main_channels_mat = self.main_channels_mat[idx,:,:]\n",
    "        symbols_store_mat = self.symbols_store_mat[idx,:]\n",
    "        return algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2a537d-4f72-4525-9d55-3f479405587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae911b39-4580-44fe-81de-864892143bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the dataset into train and remaining (val + test)\n",
    "train_set, remaining_set = train_test_split(dataset, test_size=200000, random_state=42)\n",
    "\n",
    "# Now, split the remaining set into validation and test sets\n",
    "val_set, test_set = train_test_split(remaining_set, test_size=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b372d6-28d2-4e1b-b2c7-4ecc3f46c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2425bdd-3cfc-4088-9f70-28db15772818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of batch feature is torch.Size([64, 70])\n",
      "shape of batch feature is torch.Size([64, 70])\n",
      "shape of batch feature is torch.Size([64, 10, 70])\n",
      "shape of batch feature is torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_alg_in_mat, batch_alg_out_mat, batch_main_chan_mat, batch_sym_mat = next(iter(train_loader))\n",
    "print(f'shape of batch feature is {batch_alg_in_mat.shape}')\n",
    "print(f'shape of batch feature is {batch_alg_out_mat.shape}')\n",
    "print(f'shape of batch feature is {batch_main_chan_mat.shape}')\n",
    "print(f'shape of batch feature is {batch_sym_mat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c7014c1-b68f-4c18-8080-bd6c0cc2eb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 10, 70])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.real(batch_main_chan_mat).float(), torch.imag(batch_main_chan_mat).float()], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4e0a58e-4083-4f92-a375-da27fcd11eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_interleaved_real(complex_signal):\n",
    "    real_part = complex_signal.real.to(dtype=torch.float32) \n",
    "    imag_part = complex_signal.imag.to(dtype=torch.float32) \n",
    "    interleaved_signal = torch.stack((real_part, imag_part), dim=2).reshape(complex_signal.shape[0], -1)\n",
    "    return interleaved_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa1c6bd0-3830-41ee-8f79-168a01a7530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleaved_real_to_complex(interleaved_signal):\n",
    "    signal_length = interleaved_signal.shape[1] // 2\n",
    "    real_part = interleaved_signal[:, 0::2]  # Extract even indices\n",
    "    imag_part = interleaved_signal[:, 1::2]  # Extract odd indices\n",
    "    complex_signal = torch.complex(real_part, imag_part)\n",
    "    return complex_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d85abef5-3c5a-474f-aee1-1761ae32f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_papr_complex(signal):\n",
    "    # Compute |x[n]|^2: Magnitude squared of the complex signal\n",
    "    power_signal = torch.abs(signal)**2\n",
    "    \n",
    "    # Peak power\n",
    "    peak_power_signal= torch.max(power_signal, dim=1).values\n",
    "\n",
    "    # Average power\n",
    "    avg_power_signal = torch.mean(power_signal, dim=1)\n",
    "\n",
    "    # PAPR\n",
    "    papr_signal = peak_power_signal / avg_power_signal\n",
    "    \n",
    "    return papr_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b9bb3f2-4dc6-4155-a8da-627445761686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def papr_loss(signal_going_out, signal_coming_in):\n",
    "    # Compute PAPR before and after\n",
    "    papr_going_out = compute_papr_complex(signal_going_out)  # Transformed signal\n",
    "    papr_coming_in = compute_papr_complex(signal_coming_in)  # Original signal\n",
    "\n",
    "    # Penalize only if PAPR after is greater than PAPR before\n",
    "    papr_diff = torch.relu(papr_going_out - papr_coming_in)\n",
    "    \n",
    "    return torch.mean(papr_diff), torch.mean(papr_going_out), torch.mean(papr_coming_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1d9eb3a-3856-4452-805e-ca119bfacdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_matlab(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat):\n",
    "    \n",
    "    batch_alg_in_mat_real = matlab.double(batch_alg_in_mat.real.tolist())\n",
    "    batch_alg_in_mat_imag = matlab.double(batch_alg_in_mat.imag.tolist())\n",
    "\n",
    "    batch_alg_out_mat_real = matlab.double(batch_alg_out_mat.real.tolist())\n",
    "    batch_alg_out_mat_imag = matlab.double(batch_alg_out_mat.imag.tolist())\n",
    "\n",
    "    batch_nn_out_real = matlab.double(batch_nn_out.real.tolist())\n",
    "    batch_nn_out_imag = matlab.double(batch_nn_out.imag.tolist())\n",
    "\n",
    "    batch_main_chan_mat_real = matlab.double(batch_main_chan_mat.real.tolist())\n",
    "    batch_main_chan_mat_imag = matlab.double(batch_main_chan_mat.imag.tolist())\n",
    "\n",
    "    batch_sym_mat = matlab.uint32(batch_sym_mat.tolist())\n",
    "\n",
    "    return batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag, batch_sym_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c00e4fa-534d-4ae9-977d-c5cca46a7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ser_loss(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat):\n",
    "\n",
    "    batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag , batch_sym_mat = prepare_for_matlab(batch_alg_in_mat, batch_alg_out_mat, batch_nn_out, batch_main_chan_mat, batch_sym_mat)\n",
    "    ser_mat = eng.calculate_ser(batch_alg_in_mat_real, batch_alg_in_mat_imag, batch_alg_out_mat_real, batch_alg_out_mat_imag, batch_nn_out_real, batch_nn_out_imag, batch_main_chan_mat_real, batch_main_chan_mat_imag , batch_sym_mat)\n",
    "    ser_torch = torch.tensor(ser_mat, dtype=torch.float32)\n",
    "    ser_diff = torch.relu(ser_torch[:,2] - ser_torch[:,1])\n",
    "    return torch.mean(ser_diff), torch.mean(ser_torch[:,2]), torch.mean(ser_torch[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fbc824a-e50a-4f62-a221-12b15d8a39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_complex_autocorrelation(signals):\n",
    "    signals_conj = torch.conj(signals)  # Compute complex conjugate\n",
    "    results = torch.zeros((signals.size(0), signals.size(1)), dtype=torch.cfloat)  # Output buffer\n",
    "    \n",
    "    for i in range(signals.size(0)):  # Process each signal in the batch\n",
    "        signal = signals[i]\n",
    "        signal_conj = signals_conj[i]\n",
    "        # Compute convolution (autocorrelation via convolution)\n",
    "        result = torch.nn.functional.conv1d(\n",
    "            signal.view(1, 1, -1),\n",
    "            signal_conj.flip(0).view(1, 1, -1),\n",
    "            padding=signal.size(0) - 1,\n",
    "        )\n",
    "        results[i] = result.view(-1)[signal.size(0) - 1:]  # Keep only positive lags\n",
    "\n",
    "    # Separate magnitude and phase for the batch\n",
    "    magnitudes = torch.abs(results)  # Shape: (batch_size, signal_length)\n",
    "    phases = torch.angle(results)    # Shape: (batch_size, signal_length)\n",
    "\n",
    "    # Create 2D autocorrelation maps for each signal in the batch\n",
    "    auto_maps_real = torch.einsum('bi,bj->bij', torch.real(results), torch.real(results))\n",
    "    auto_maps_imag = torch.einsum('bi,bj->bij', torch.imag(results), torch.imag(results))\n",
    "    auto_maps_mag = torch.einsum('bi,bj->bij', magnitudes, magnitudes)  # Outer product: (batch_size, signal_length, signal_length)\n",
    "    auto_maps_phase = torch.einsum('bi,bj->bij', phases, phases)  # Outer product: (batch_size, signal_length, signal_length)\n",
    "\n",
    "    # Normalize maps to [0, 1]\n",
    "    auto_maps_real_normalized = (auto_maps_real - auto_maps_real.min()) / (auto_maps_real.max() - auto_maps_real.min())\n",
    "    auto_maps_imag_normalized = (auto_maps_imag - auto_maps_imag.min()) / (auto_maps_imag.max() - auto_maps_imag.min())\n",
    "    auto_maps_mag_normalized = (auto_maps_mag - auto_maps_mag.min()) / (auto_maps_mag.max() - auto_maps_mag.min())\n",
    "    auto_maps_phase_normalized = (auto_maps_phase - auto_maps_phase.min()) / (auto_maps_phase.max() - auto_maps_phase.min())\n",
    "\n",
    "    output = torch.cat([auto_maps_real_normalized.unsqueeze(1), auto_maps_imag_normalized.unsqueeze(1), auto_maps_mag_normalized.unsqueeze(1), auto_maps_phase_normalized.unsqueeze(1)], dim = 1)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6184ba22-19fb-45d0-8f85-b22d7154707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 70])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_alg_out_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "477272b0-eec4-44ca-a3d8-3da043e9716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_out = batch_complex_autocorrelation(batch_alg_out_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1b5cacf-3d01-4e47-a402-6190caaf6933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 70, 70])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50c9a202-ef06-450d-8f24-5b45a3b2833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CSIModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=32, kernel_size=3, stride=1, padding=2)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bnconv1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bnconv2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear1 = nn.Linear(1728, 280)\n",
    "        self.bnlin1 = nn.BatchNorm1d(280)\n",
    "        \n",
    "        self.linear2 = nn.Linear(280, 140)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(1)\n",
    "        x = F.relu(self.bnconv1(self.maxpool1(self.conv1(x))))\n",
    "        x = F.relu(self.bnconv2(self.maxpool2(self.conv2(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.bnlin1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f172b873-cecf-4482-8078-3ca48377dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_1 = CSIModel()(torch.rand([64,2,10,70]))\n",
    "#test_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6118a666-2b05-438a-b0fd-1a6bf211e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SignalModel, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(140, 140)\n",
    "        self.bnlin1 = nn.BatchNorm1d(140)\n",
    "        \n",
    "        self.linear2 = nn.Linear(140, 140)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(1)\n",
    "        x = F.relu(self.bnlin1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c3feb30-605e-4825-b759-28012418e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_2 = SignalModel()(torch.rand([64,140]))\n",
    "#test_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44034148-83aa-4850-8664-96eb20b0ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = torch.cat([test_output_1, test_output_2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f775d6c0-e37f-4819-b41b-22c3caa394f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 280])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5466786c-718c-4e14-8f8b-6d95defefb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        \n",
    "        self.csimodel = CSIModel()\n",
    "        self.signalmodel = SignalModel()\n",
    "\n",
    "        \n",
    "        self.linear1 = nn.Linear(280,140)\n",
    "        self.bnlin1 = nn.BatchNorm1d(140)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        #x = x.unsqueeze(1)\n",
    "        x1 = self.csimodel(x1)\n",
    "        x2 = self.signalmodel(x2)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.bnlin1(self.linear1(x))\n",
    "  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4c5b24b-b561-4ae2-be90-4053d43d8a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 140])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_final= CombinedModel()(torch.rand([64,2,10,70]), torch.rand([64,140]))\n",
    "test_output_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b8f3f7a-be21-46f2-8754-23dc991b56ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10] T Loss:0.1646 PAPR_dff: 0.0006 NN_PAPR: 1.7089 Alg_PAPR: 2.1211 SER_dff: 0.9344 NN_SER: 0.9344 Alg_SER: 0.0000 LR is 0.001: 100%|█| 7813"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10] V Loss:0.0080 PAPR_dff: 0.0000 NN_PAPR: 1.6889 Alg_PAPR: 2.1117 SER_dff: 0.9219 NN_SER: 0.9219 Alg_SER: 0.0000: 100%|█| 1563/1563 [00:24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0080 at Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10] T Loss:0.1018 PAPR_dff: 0.0000 NN_PAPR: 1.7370 Alg_PAPR: 2.0894 SER_dff: 0.9375 NN_SER: 0.9438 Alg_SER: 0.0063 LR is 0.001: 100%|█| 7813"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10] V Loss:0.0079 PAPR_dff: 0.0000 NN_PAPR: 1.7446 Alg_PAPR: 2.1117 SER_dff: 0.9219 NN_SER: 0.9219 Alg_SER: 0.0000: 100%|█| 1563/1563 [00:27"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss is now: 0.0079 at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10] T Loss:0.1025 PAPR_dff: 0.0000 NN_PAPR: 1.7252 Alg_PAPR: 2.1503 SER_dff: 0.9219 NN_SER: 0.9219 Alg_SER: 0.0000 LR is 0.001: 100%|█| 7813"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10] V Loss:0.0127 PAPR_dff: 0.0000 NN_PAPR: 1.7223 Alg_PAPR: 2.1117 SER_dff: 0.9500 NN_SER: 0.9531 Alg_SER: 0.0031: 100%|█| 1563/1563 [00:31"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Epoch: 1 without improvement\n",
      "Current Validation Loss is: 0.0127 at Epoch: 3\n",
      "Best Validation Loss remains: 0.0079 at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10] T Loss:0.1030 PAPR_dff: 0.0000 NN_PAPR: 1.7179 Alg_PAPR: 2.1090 SER_dff: 0.8937 NN_SER: 0.8938 Alg_SER: 0.0000 LR is 0.001: 100%|█| 7813"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has completed epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10] V Loss:0.0119 PAPR_dff: 0.0000 NN_PAPR: 1.7222 Alg_PAPR: 2.1117 SER_dff: 0.9344 NN_SER: 0.9375 Alg_SER: 0.0031: 100%|█| 1563/1563 [00:25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Epoch: 2 without improvement\n",
      "Current Validation Loss is: 0.0119 at Epoch: 4\n",
      "Best Validation Loss remains: 0.0079 at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10] T Loss:0.1051 PAPR_dff: 0.0054 NN_PAPR: 1.7152 Alg_PAPR: 2.1028 SER_dff: 0.9203 NN_SER: 0.9234 Alg_SER: 0.0031 LR is 0.001:   2%| | 135/"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     56\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 57\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Update running loss\u001b[39;00m\n\u001b[1;32m     60\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/adam.py:379\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    378\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 379\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    382\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CombinedModel().to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "loss = torch.nn.MSELoss()  # For classification\n",
    "\n",
    "# Define an optimizer (both for the encoder and the decoder!)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.01)  # Learning rate decay scheduler\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2)\n",
    "\n",
    "# Variables for early stopping and best parameters\n",
    "best_loss = float('inf')\n",
    "patience_limit = 2\n",
    "\n",
    "\n",
    "best_model = None\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "alpha = 1\n",
    "beta = 0.1\n",
    "gamma = 0.1\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    progress_bar_train = tqdm(enumerate(train_loader), total=len(train_loader), ncols=150)\n",
    "    for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_train:\n",
    "        # Forward pass\n",
    "        #algorithm_output_mat_for_nn = (batch_complex_autocorrelation(algorithm_output_mat)).to(device)\n",
    "        main_channels_mat_for_nn = torch.stack([torch.real(main_channels_mat).float(), torch.imag(main_channels_mat).float()], dim=1).to(device)\n",
    "        algorithm_input_mat_for_nn = (complex_to_interleaved_real(algorithm_input_mat)).to(device)\n",
    "        algorithm_output_mat_for_nn = (complex_to_interleaved_real(algorithm_output_mat)).to(device)\n",
    "\n",
    "        \n",
    "        nn_output = model(main_channels_mat_for_nn, algorithm_input_mat_for_nn)\n",
    "        \n",
    "        # Calculate loss\n",
    "        initial_loss = loss(nn_output, algorithm_output_mat_for_nn)\n",
    "\n",
    "        nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "        algorithm_output_mat_for_nn_control =  interleaved_real_to_complex(algorithm_output_mat_for_nn)\n",
    "        \n",
    "        papr_diff, nn_papr, alg_papr  = papr_loss(nn_output_control, algorithm_output_mat_for_nn_control)\n",
    "        ser_diff, nn_ser, alg_ser = ser_loss(algorithm_input_mat, algorithm_output_mat_for_nn_control, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "        \n",
    "        train_loss = alpha*initial_loss + beta*papr_diff + gamma*ser_diff\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_train_loss += train_loss.item()\n",
    "        avg_train_loss = running_train_loss / (index + 1)\n",
    "\n",
    "        # Get current learning rate from the optimizer\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Print metrics\n",
    "        #progress_bar_train.set_description(f'Epoch [{epoch + 1}/{EPOCHS}] MSELos:{avg_train_loss1:.4f} MSEWeig{mse_weight:.2f} CELos:{avg_train_loss2:.4f} CEWeig{ce_weight:.2f} TrLos:{avg_train_loss:.4f} Tr.Acc: {avg_train_acc*100:.2f}%')\n",
    "        progress_bar_train.set_description(f\" Epoch [{epoch + 1}/{EPOCHS}] T Loss:{avg_train_loss:.4f} PAPR_dff: {papr_diff:.4f} NN_PAPR: {nn_papr:.4f} Alg_PAPR: {alg_papr:.4f} SER_dff: {ser_diff:.4f} NN_SER: {nn_ser:.4f} Alg_SER: {alg_ser:.4f} LR is {current_lr}\")\n",
    "    \n",
    "    #train_losses.append(avg_train_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Training has completed epoch {epoch+1}\")\n",
    "    \n",
    "    # Validation loop\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    progress_bar_val = tqdm(enumerate(val_loader), total=len(val_loader), ncols=150)\n",
    "    for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_val:\n",
    "        \n",
    "        #algorithm_output_mat_for_nn = (batch_complex_autocorrelation(algorithm_output_mat)).to(device)\n",
    "        main_channels_mat_for_nn = torch.stack([torch.real(main_channels_mat).float(), torch.imag(main_channels_mat).float()], dim=1).to(device)\n",
    "        algorithm_input_mat_for_nn = (complex_to_interleaved_real(algorithm_input_mat)).to(device)\n",
    "        algorithm_output_mat_for_nn = (complex_to_interleaved_real(algorithm_output_mat)).to(device)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            nn_output = model(main_channels_mat_for_nn, algorithm_input_mat_for_nn)\n",
    "\n",
    "            # Calculate losses\n",
    "            val_loss = loss(nn_output, algorithm_output_mat_for_nn)\n",
    "\n",
    "            # Update running loss\n",
    "            running_val_loss += val_loss.item()\n",
    "            \n",
    "            avg_val_loss = running_val_loss / (index + 1)\n",
    "\n",
    "            nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "            algorithm_output_mat_for_nn_control =  interleaved_real_to_complex(algorithm_output_mat_for_nn)\n",
    "        \n",
    "            papr_diff, nn_papr, alg_papr = papr_loss(nn_output_control, algorithm_output_mat_for_nn_control)\n",
    "            ser_diff, nn_ser, alg_ser = ser_loss(algorithm_input_mat, algorithm_output_mat_for_nn_control, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "\n",
    "            progress_bar_val.set_description(f\" Epoch [{epoch + 1}/{EPOCHS}] V Loss:{avg_val_loss:.4f} PAPR_dff: {papr_diff:.4f} NN_PAPR: {nn_papr:.4f} Alg_PAPR: {alg_papr:.4f} SER_dff: {ser_diff:.4f} NN_SER: {nn_ser:.4f} Alg_SER: {alg_ser:.4f}\")\n",
    "    \n",
    "    #val_losses.append(avg_val_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    scheduler.step(running_val_loss)\n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_loss:  # Now checking for the best accuracy\n",
    "        best_loss = avg_val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        best_train_loss = avg_train_loss\n",
    "        patience_ = 0\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "        print(f\"Best Validation Loss is now: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "    else:\n",
    "        patience_ += 1\n",
    "        print(f\"This is Epoch: {patience_} without improvement\")\n",
    "        print(f\"Current Validation Loss is: {avg_val_loss:.4f} at Epoch: {epoch+1}\")\n",
    "        print(f\"Best Validation Loss remains: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "        if patience_ > patience_limit:  # Patience limit before stopping\n",
    "            print(\"Early stopping triggered! Restoring best model weights.\")\n",
    "            print(f\"Best Validation Loss was: {best_loss:.4f} at Epoch: {best_epoch}\")\n",
    "            break\n",
    "\n",
    "best_model = model.cpu()\n",
    "best_model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "830b9432-9787-4c17-ab5c-d7d6378506d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 0%|                                                                                                                        | 0/1563 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m algorithm_output_mat_for_nn \u001b[38;5;241m=\u001b[39m (complex_to_interleaved_real(algorithm_output_mat))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 14\u001b[0m     nn_output \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_channels_mat_for_nn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm_input_mat_for_nn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Calculate losses\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m loss(nn_output, algorithm_output_mat_for_nn)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "running_test_loss = 0.0\n",
    "\n",
    "\n",
    "progress_bar_test = tqdm(enumerate(test_loader), total=len(test_loader), ncols=150)\n",
    "for index, (algorithm_input_mat, algorithm_output_mat, main_channels_mat, symbols_store_mat) in progress_bar_test:\n",
    "        \n",
    "    main_channels_mat_for_nn = torch.stack([torch.real(main_channels_mat).float(), torch.imag(main_channels_mat).float()], dim=1)\n",
    "    algorithm_input_mat_for_nn = (complex_to_interleaved_real(algorithm_input_mat))\n",
    "    algorithm_output_mat_for_nn = (complex_to_interleaved_real(algorithm_output_mat))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            \n",
    "        nn_output = best_model(main_channels_mat_for_nn, algorithm_input_mat_for_nn)\n",
    "\n",
    "        # Calculate losses\n",
    "        test_loss = loss(nn_output, algorithm_output_mat_for_nn)\n",
    "\n",
    "        # Update running loss\n",
    "        running_test_loss += test_loss.item()\n",
    "            \n",
    "        avg_test_loss = running_test_loss / (index + 1)\n",
    "\n",
    "        nn_output_control =  interleaved_real_to_complex(nn_output)\n",
    "        algorithm_output_mat_for_nn_control =  interleaved_real_to_complex(algorithm_output_mat_for_nn)\n",
    "        \n",
    "        papr_diff, nn_papr, alg_papr = papr_loss(nn_output_control, algorithm_output_mat_for_nn_control)\n",
    "        ser_diff, nn_ser, alg_ser = ser_loss(algorithm_input_mat, algorithm_output_mat_for_nn_control, nn_output_control, main_channels_mat, symbols_store_mat)\n",
    "\n",
    "        progress_bar_test.set_description(f'Epoch [{epoch + 1}/{EPOCHS}] Te Loss:{avg_test_loss:.4f} PAPR_dff: {papr_diff:.4f} SER_dff: {ser_diff:.4f}')\n",
    "\n",
    "        \n",
    "        if index < 1:\n",
    "            total_nn_out = nn_output_control\n",
    "            total_alg_in = algorithm_input_mat\n",
    "            total_alg_out = algorithm_output_mat_for_nn_control\n",
    "            total_main_channels = main_channels_mat\n",
    "            total_symbols = symbols_store_mat\n",
    "        else:\n",
    "            total_nn_out = torch.cat([total_nn_out, nn_output_control], dim=0, out=None)\n",
    "            total_alg_in = torch.cat([total_alg_in, algorithm_input_mat], dim=0, out=None)\n",
    "            total_alg_out = torch.cat([total_alg_out, algorithm_output_mat_for_nn_control], dim=0, out=None)\n",
    "            total_main_channels = torch.cat([total_main_channels, main_channels_mat], dim=0, out=None)\n",
    "            total_symbols = torch.cat([total_symbols, symbols_store_mat], dim=0, out=None)\n",
    "\n",
    "test_losses.append(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "66f020a4-b573-4f70-8d66-dab90fc0de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_alg_in_real, total_alg_in_imag, total_alg_out_real, total_alg_out_imag, total_nn_out_real, total_nn_out_imag, total_main_channels_real, total_main_channels_imag, total_symbols = prepare_for_matlab(total_alg_in, total_alg_out, total_nn_out, total_main_channels, total_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6f0d677f-c655-4a98-9636-1955d4cdc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all variables in a dictionary\n",
    "savemat(\"output_from_pytorch.mat\", {\n",
    "    \"total_alg_in_real\": total_alg_in_real,\n",
    "    \"total_alg_in_imag\": total_alg_in_imag,\n",
    "    \"total_alg_out_real\": total_alg_out_real,\n",
    "    \"total_alg_out_imag\": total_alg_out_imag,\n",
    "    \"total_nn_out_real\": total_nn_out_real,\n",
    "    \"total_nn_out_imag\": total_nn_out_imag,\n",
    "    \"total_main_channels_real\": total_main_channels_real,\n",
    "    \"total_main_channels_imag\": total_main_channels_imag,\n",
    "    \"total_symbols\": total_symbols\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e49995-da2d-4b44-ad81-59217a411746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
